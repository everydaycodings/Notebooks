{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "reqUrl = \"https://internshala.com/jobs/page-1/\"\n",
    "\n",
    "headersList = {\n",
    " \"Accept\": \"*/*\",\n",
    " \"User-Agent\": \"Thunder Client (https://www.thunderclient.com)\" \n",
    "}\n",
    "\n",
    "payload = \"\"\n",
    "\n",
    "response = requests.request(\"GET\", reqUrl, data=payload,  headers=headersList)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Title: Business Development Associate\n",
      "Company Name: Break The Code\n",
      "Location: Mumbai\n",
      "Start Date: Starts Immediately\n",
      "CTC (Annual): ₹ 2,00,000 - 3,00,000\n",
      "Experience: 0-1 years\n",
      "Posted Time: 3 days ago\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nested_divs = soup.find_all('div', class_='container-fluid individual_internship visibilityTrackerItem')\n",
    "\n",
    "for soup in nested_divs:\n",
    "\n",
    "      job_title = soup.find('h3', class_='heading_4_5 profile').a.text.strip()\n",
    "      company_name = soup.find('h4', class_='heading_6 company_name').a.text.strip()\n",
    "\n",
    "      # Extracting location\n",
    "      location = soup.find('p', id='location_names').span.text.strip()#.text.strip()\n",
    "\n",
    "      # Extracting start date\n",
    "      start_date = soup.find('div', class_='item_body', id='start-date-first').text.strip()\n",
    "\n",
    "      # Extracting CTC (Annual)\n",
    "      ctc = soup.find('div', class_='item_body salary').select_one('span.desktop').text.strip()\n",
    "\n",
    "      # Extracting experience\n",
    "      experience = soup.find('div', class_='item_body desktop-text').text.strip()\n",
    "\n",
    "      # Extracting posted time\n",
    "      posted_time = soup.find('div', class_='status-container').text.strip()\n",
    "\n",
    "\n",
    "      # Extracting job type\n",
    "      job_type = soup.find('div', class_='status status-small status-inactive').text.strip()\n",
    "\n",
    "      # Print or use the extracted information as needed\n",
    "      print(\"Job Title:\", job_title)\n",
    "      print(\"Company Name:\", company_name)\n",
    "      print(\"Location:\", location)\n",
    "      print(\"Start Date:\", start_date)\n",
    "      print(\"CTC (Annual):\", ctc)\n",
    "      print(\"Experience:\", experience)\n",
    "      print(\"Posted Time:\", posted_time)\n",
    "      break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbname = \"postgres\"\n",
    "user = \"saksham\"\n",
    "password = \"everydaycodings*189100\"\n",
    "host = \"news-api-data.postgres.database.azure.com\"\n",
    "port = 5432\n",
    "table_name = \"job\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import requests\n",
    "from psycopg2 import sql\n",
    "\n",
    "\n",
    "def connect_to_database(dbname, user, password, host, port):\n",
    "        # Establish a connection\n",
    "        conn = psycopg2.connect(dbname=dbname, user=user, password=password, host=host, port=port)\n",
    "\n",
    "        # Create a cursor object to execute SQL queries\n",
    "        return conn\n",
    "\n",
    "\n",
    "def push_data(data, conn, table_name):\n",
    "    insert_query = sql.SQL(\"\"\"\n",
    "        INSERT INTO {} \n",
    "        (Job_Title, Company_Name, Location, Start_Date, CTC, Experience, Posted)\n",
    "        VALUES \n",
    "        (%(Job_Title)s, %(Company_Name)s, %(Location)s, %(Start_Date)s, %(CTC)s, %(Experience)s, %(Posted Time)s)\n",
    "    \"\"\").format(sql.Identifier(table_name))\n",
    "\n",
    "    # Create a cursor and execute the insert query\n",
    "    with conn.cursor() as cursor:\n",
    "        cursor.execute(insert_query, data)\n",
    "\n",
    "    # Commit the changes to the database\n",
    "    conn.commit()\n",
    "\n",
    "conn = connect_to_database(dbname, user, password, host, port)\n",
    "def process(num):\n",
    "\n",
    "    reqUrl = \"https://internshala.com/jobs/page-{}/\".format(num)\n",
    "\n",
    "    headersList = {\n",
    "    \"Accept\": \"*/*\",\n",
    "    \"User-Agent\": \"Thunder Client (https://www.thunderclient.com)\" \n",
    "    }\n",
    "\n",
    "    payload = \"\"\n",
    "\n",
    "    response = requests.request(\"GET\", reqUrl, data=payload,  headers=headersList)\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    nested_divs = soup.find_all('div', class_='container-fluid individual_internship visibilityTrackerItem')\n",
    "\n",
    "    for target_div in nested_divs:\n",
    "        \n",
    "        try:\n",
    "            job_title = target_div.find('h3', class_='heading_4_5 profile').a.text.strip()\n",
    "        except:\n",
    "              job_title = \"None\"\n",
    "        \n",
    "        try:\n",
    "            company_name = target_div.find('h4', class_='heading_6 company_name').a.text.strip()\n",
    "        except:\n",
    "            company_name = \"None\"\n",
    "\n",
    "\n",
    "        try:    \n",
    "            # Extracting location\n",
    "            location = target_div.find('p', id='location_names').span.text.strip()\n",
    "        except:\n",
    "            location = \"None\"\n",
    "\n",
    "        try:\n",
    "            # Extracting start date\n",
    "            start_date = target_div.find('div', class_='item_body', id='start-date-first').text.strip()\n",
    "        except:\n",
    "            start_date = \"None\"\n",
    "\n",
    "        try:\n",
    "            # Extracting CTC (Annual)\n",
    "            ctc = target_div.find('div', class_='item_body salary').select_one('span.desktop').text.strip()\n",
    "        except:\n",
    "            ctc = \"None\"\n",
    "\n",
    "        try:\n",
    "            # Extracting experience\n",
    "            experience = target_div.find('div', class_='item_body desktop-text').text.strip()\n",
    "        except:\n",
    "            experience = \"None\"\n",
    "\n",
    "        try:\n",
    "            # Extracting posted time\n",
    "            posted_time = target_div.find('div', class_='status-container').text.strip()\n",
    "        except:\n",
    "            posted_time = \"None\"\n",
    "\n",
    "\n",
    "        data_dict = {\n",
    "            'Job_Title': job_title,\n",
    "            'Company_Name': company_name,\n",
    "            'Location': location,\n",
    "            'Start_Date': start_date,\n",
    "            'Experience': experience,\n",
    "            'CTC':  ctc,\n",
    "            'Posted Time': posted_time\n",
    "            }\n",
    "        # Assuming conn is your database connection\n",
    "        push_data(data_dict, conn, table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 200):\n",
    "    process(i)\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
